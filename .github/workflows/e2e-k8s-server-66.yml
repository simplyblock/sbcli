name: E2E Test K8s on 192.168.10.66

on:
  push:
    branches:
      - pre-release
      - sbcli

  workflow_dispatch:
    inputs:
      simplyBlockDeploy_branch:
        description: 'Branch for simplyBlockDeploy'
        required: true
        default: 'vmware'
      sbcli_cmd:
        description: 'Command for sbcli execution'
        required: true
        default: 'sbcli-dev'
      testname:
        description: 'Name of test to run. Empty to run all'
        required: false
        default: ''
      ndcs:
        description: 'Value for NDCS'
        required: false
        default: 1
      npcs:
        description: 'Value for NPCS'
        required: false
        default: 1
      bs:
        description: 'Value for Block size'
        required: false
        default: 4096
      chunk_bs:
        description: 'Value for Chunk block size'
        required: false
        default: 4096
      send_slack_notification:
        description: 'Send Slack notification?'
        required: false
        default: false
        type: boolean
      cleanup_cluster:
        description: 'Cleanup Cluster'
        required: false
        default: true
        type: boolean
      run_ha_test:
        description: 'Run HA tests or not'
        required: false
        default: true
        type: boolean

jobs:
  e2e:
    runs-on: vm22
    concurrency:
      group: ${{ github.workflow }}
      cancel-in-progress: false
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set send_slack_notification for scheduled and push events
        if: github.event_name == 'schedule' || github.event_name == 'push'
        run: echo "send_slack_notification=true" >> $GITHUB_ENV

      - name: Set send_slack_notification for manual workflow_dispatch
        if: github.event_name == 'workflow_dispatch'
        run: echo "send_slack_notification=${{ github.event.inputs.send_slack_notification }}" >> $GITHUB_ENV

      - name: Set cleanup_cluster for scheduled and push events
        if: github.event_name == 'schedule' || github.event_name == 'push'
        run: echo "cleanup_cluster=true" >> $GITHUB_ENV

      - name: Set cleanup_cluster for manual workflow_dispatch
        if: github.event_name == 'workflow_dispatch'
        run: echo "cleanup_cluster=${{ github.event.inputs.cleanup_cluster }}" >> $GITHUB_ENV

      - uses: actions/setup-go@v5
        with:
          go-version: '1.22'
      - run: go version

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      - uses: actions/checkout@master
        name: Checkout code simplyBlockDeploy
        with:
          repository: simplyblock-io/simplyBlockDeploy
          ref: refs/heads/${{ github.event.inputs.simplyBlockDeploy_branch || 'main'}}
          path: 'simplyBlockDeploy'
          token: ${{ secrets.GH_ACCESS_KEY_ID_RAUNAK }}
      
      - uses: actions/checkout@master
        name: Checkout code simplyblock_csi_branch
        with:
          repository: simplyblock-io/simplyblock-csi
          ref: refs/heads/${{ github.event.inputs.simplyblock_csi_branch || 'master'}}
          path: 'simplyblock-csi'
          token: ${{ secrets.GH_ACCESS_KEY_ID_RAUNAK }}

      - name: Install Helm v3.15.4
        run: |
          curl -L https://get.helm.sh/helm-v3.15.4-linux-amd64.tar.gz -o helm-v3.15.4-linux-amd64.tar.gz
          tar -zxvf helm-v3.15.4-linux-amd64.tar.gz
          sudo mv linux-amd64/helm /usr/local/bin/helm
          helm version

      - name: Install kubectl v1.31.0
        run: |
          curl -LO "https://dl.k8s.io/release/v1.31.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          kubectl version --client

      - name: Set parameters based on branch and input
        run: |
          if [[ "${GITHUB_REF##*/}" == *"pre-release"* ]]; then
            echo "Branch is pre-release. Setting SBCLI_CMD to sbcli-pre."
            echo "SBCLI_CMD=sbcli-pre" >> $GITHUB_ENV
          elif [[ "${GITHUB_REF##*/}" == "sbcli" ]]; then
            echo "Branch is sbcli. Setting SBCLI_CMD to sbcli."
            echo "SBCLI_CMD=sbcli" >> $GITHUB_ENV
          else
            echo "Setting SBCLI_CMD to input or default to sbcli-dev."
            echo "SBCLI_CMD=${{ github.event.inputs.sbcli_cmd || 'sbcli-dev' }}" >> $GITHUB_ENV
          fi
          echo "NDCS=${{ github.event.inputs.ndcs || 2 }}" >> $GITHUB_ENV
          echo "NPCS=${{ github.event.inputs.npcs || 1 }}" >> $GITHUB_ENV
          echo "BS=${{ github.event.inputs.bs || 4096 }}" >> $GITHUB_ENV
          echo "CHUNK_BS=${{ github.event.inputs.chunk_bs || 4096 }}" >> $GITHUB_ENV
        shell: bash

      - name: Uninstall K3s agent on all nodes
        if: always() && (github.event_name == 'schedule' || env.cleanup_cluster == 'true')
        run: |
          helm uninstall -n spdk-csi spdk-csi || echo "No helm release found. Skipping uninstall."
          
          echo "[INFO] Deleting deployments..."
          kubectl delete deployments --all -n spdk-csi || echo "No deployments found. Skipping delete deployment."
          
          echo "[INFO] Deleting daemonsets..."
          kubectl delete daemonset --all -n spdk-csi || echo "No daemonsets found. Skipping delete."
          
          echo "[INFO] Deleting all pods..."
          kubectl delete pods --all -n spdk-csi --force --timeout=10s || echo "Pods not deleted within timeout."

          echo "[INFO] Waiting for all resources to be deleted..."
          timeout=120  # Max wait time (in seconds)
          interval=5  # Check every 5 seconds
          elapsed=0

          while [[ $(kubectl get all -n spdk-csi --no-headers 2>/dev/null | wc -l) -gt 0 && $elapsed -lt $timeout ]]; do
            echo "[INFO] Waiting for resources to be deleted... Elapsed: ${elapsed}s"
            sleep $interval
            elapsed=$((elapsed + interval))
          done

          if [[ $(kubectl get all -n spdk-csi --no-headers 2>/dev/null | wc -l) -eq 0 ]]; then
            echo "[SUCCESS] All resources deleted successfully."
          else
            echo "[WARNING] Resources were not deleted within the timeout of ${timeout}s."
          fi

          for node in $K3S_MNODES $STORAGE_PRIVATE_IPS $SEC_STORAGE_PRIVATE_IPS; do
            ssh -i ~/.ssh/simplyblock-us-east-2.pem  root@${node} "k3s-agent-uninstall.sh" || echo "[WARNING] K3s-agent-uninstall failed on $node"
          done
          
          for node in $MNODES; do
            if ssh -i ~/.ssh/simplyblock-us-east-2.pem root@${node} "command -v $SBCLI_CMD" &>/dev/null; then
              ssh -i ~/.ssh/simplyblock-us-east-2.pem root@${node} "$SBCLI_CMD sn deploy-cleaner" || echo "[WARNING] Failed to run deploy-cleaner on $node"
            else
              echo "[WARNING] SBCLI_CMD not found on $node. Skipping deploy-cleaner."
            fi

            ssh -i ~/.ssh/simplyblock-us-east-2.pem root@${node} "rm -rf /etc/foundationdb/* || true" || echo "[WARNING] Failed to clean foundationdb on $node"
          done
        env:
          STORAGE_PRIVATE_IPS: "192.168.10.67 192.168.10.68 192.168.10.69"
          SEC_STORAGE_PRIVATE_IPS: "192.168.10.70"
          MNODES: "192.168.10.66"
          SBCLI_CMD: ${{ env.SBCLI_CMD }}


      - name: Bootstrap Cluster
        run: |
          cd $GITHUB_WORKSPACE/simplyBlockDeploy

          ./bootstrap-cluster.sh --sbcli-cmd "$SBCLI_CMD" \
            --max-lvol 20 --max-snap 20 --max-prov 150G --number-of-devices 3 \
            --distr-ndcs $NDCS \
            --distr-npcs $NPCS \
            --distr-bs $BS \
            --distr-chunk-bs $CHUNK_BS --ha-type ha \
            --partitions 0 --k8s-snode
            
          echo "::set-output name=bastion_public_ip::$BASTION_IP"
          echo "::set-output name=key_name::$KEY_NAME"
          echo "::set-output name=mnodes::$MNODES"
          echo "::set-output name=storage_private_ips::$STORAGE_PRIVATE_IPS"

          ssh -i ~/.ssh/simplyblock-us-east-2.pem -o StrictHostKeyChecking=no root@${MNODES} <<EOF
          iptables -P INPUT ACCEPT
          iptables -P OUTPUT ACCEPT
          iptables -P FORWARD ACCEPT
          iptables -F
          EOF

          ./bootstrap-k3s.sh --k8s-snode

        id: bootstrap_cluster
        env:
          SBCLI_CMD: ${{ env.SBCLI_CMD }}
          NDCS: ${{ env.NDCS }}
          NPCS: ${{ env.NPCS }}
          BS: ${{ env.BS }}
          CHUNK_BS: ${{ env.CHUNK_BS }}
          KEY_NAME: "simplyblock-us-east-2.pem"
          SECRET_VALUE: ${{ secrets.simplyblock_us_east_2_pem }}
          BASTION_IP: "192.168.10.66"
          GRAFANA_ENDPOINT: "http://192.168.10.66/grafana"
          MNODES: "192.168.10.66"
          STORAGE_PRIVATE_IPS: "192.168.10.67 192.168.10.68 192.168.10.69"
          SEC_STORAGE_PRIVATE_IPS: "192.168.10.70"
          API_INVOKE_URL: "http://192.168.10.66/"
          K3S_MNODES: "192.168.10.135"
          NR_HUGEPAGES: "2048"

      - name: Configure Kubeconfig
        run: |
          mkdir -p $HOME/.kube/
          scp -i ~/.ssh/simplyblock-us-east-2.pem root@$K3S_MNODES:/etc/rancher/k3s/k3s.yaml $HOME/.kube/config
          sed -i "s/server: https:\/\/\(localhost\|127.0.0.1\)\(:[0-9]*\)/server: https:\/\/${K3S_MNODES}\2/" $HOME/.kube/config
        env:
          K3S_MNODES: "192.168.10.135"

      - name: Retrieve Cluster Details
        id: retrieve_cluster_details
        run: |
          CLUSTER_ID=$(ssh -i ~/.ssh/simplyblock-us-east-2.pem -o StrictHostKeyChecking=no root@$MNODES "$SBCLI_CMD cluster list | grep simplyblock | awk '{print \$2}'")
          CLUSTER_SECRET=$(ssh -i ~/.ssh/simplyblock-us-east-2.pem -o StrictHostKeyChecking=no root@$MNODES "$SBCLI_CMD cluster get-secret $CLUSTER_ID")

          echo "CLUSTER_ID=$CLUSTER_ID" >> $GITHUB_ENV
          echo "CLUSTER_SECRET=$CLUSTER_SECRET" >> $GITHUB_ENV
        env:
          SBCLI_CMD: ${{ env.SBCLI_CMD }}
          MNODES: "192.168.10.66"

      - name: Validate Helm Chart Before Deploying
        run: |
          cd simplyblock-csi/charts/latest/spdk-csi
          echo "Validating Helm template..."
          helm template spdk-csi ./ \
            --namespace spdk-csi \
            --set csiConfig.simplybk.uuid="${CLUSTER_ID}" \
            --set csiConfig.simplybk.ip="${API_INVOKE_URL}" \
            --set csiSecret.simplybk.secret="${CLUSTER_SECRET}" \
            --set image.simplyblock.repository="public.ecr.aws/simply-block/simplyblock" \
            --set image.spdkcsi.repository="public.ecr.aws/simply-block/spdkcsi" \
            --set image.storageNode.repository="public.ecr.aws/simply-block/storage-node-handler" \
            --set image.mgmtAPI.repository="public.ecr.aws/simply-block/python" \
            --set image.mgmtAPI.tag="3.10" \
            --set image.simplyblock.tag="main" \
            --set logicalVolume.pool_name="testing1" \
            --set logicalVolume.snapshot="True" \
            --set image.spdkcsi.tag=latest \
            --set logicalVolume.distr_ndcs="${NDCS}" \
            --set logicalVolume.distr_npcs="${NPCS}" \
            --set storagenode.create=true \
            --set cachingnode.create=false \
            --set logicalVolume.encryption=true \
            --set storagenode.maxLvol="20" \
            --set storagenode.maxSnap="20" \
            --set storagenode.maxProv="150G" \
            --set storagenode.numDevices="3" \
            --set storagenode.dataNics=eth1 \
            --set storagenode.ifname=eth0 > helm-rendered.yaml

          echo "Helm template successfully generated."
          head -n 20 helm-rendered.yaml
        env:
          SBCLI_CMD: ${{ env.SBCLI_CMD }}
          NDCS: ${{ env.NDCS }}
          NPCS: ${{ env.NPCS }}
          BS: ${{ env.BS }}
          CHUNK_BS: ${{ env.CHUNK_BS }}
          KEY_NAME: "simplyblock-us-east-2.pem"
          SECRET_VALUE: ${{ secrets.simplyblock_us_east_2_pem }}
          BASTION_IP: "192.168.10.66"
          GRAFANA_ENDPOINT: "http://192.168.10.66/grafana"
          MNODES: "192.168.10.66"
          STORAGE_PRIVATE_IPS: "192.168.10.67 192.168.10.68 192.168.10.69"
          SEC_STORAGE_PRIVATE_IPS: "192.168.10.70"
          API_INVOKE_URL: "http://192.168.10.66/"
          K3S_MNODES: "192.168.10.135"
          NR_HUGEPAGES: "2048"

      - name: Deploy SPDK-CSI with Helm
        run: |
          cd simplyblock-csi/charts/latest/spdk-csi
          echo "Running Helm Install..."
          set -x  # Enable command tracing
          helm install spdk-csi ./ \
            --namespace spdk-csi \
            --create-namespace \
            --set csiConfig.simplybk.uuid="${CLUSTER_ID}" \
            --set csiConfig.simplybk.ip="${API_INVOKE_URL}" \
            --set csiSecret.simplybk.secret="${CLUSTER_SECRET}" \
            --set image.simplyblock.repository="public.ecr.aws/simply-block/simplyblock" \
            --set image.spdkcsi.repository="public.ecr.aws/simply-block/spdkcsi" \
            --set image.storageNode.repository="public.ecr.aws/simply-block/storage-node-handler" \
            --set image.mgmtAPI.repository="public.ecr.aws/simply-block/python" \
            --set image.mgmtAPI.tag="3.10" \
            --set image.simplyblock.tag="main" \
            --set logicalVolume.pool_name="testing1" \
            --set logicalVolume.snapshot="True" \
            --set image.spdkcsi.tag=latest \
            --set logicalVolume.distr_ndcs="${NDCS}" \
            --set logicalVolume.distr_npcs="${NPCS}" \
            --set storagenode.create=true \
            --set cachingnode.create=false \
            --set logicalVolume.encryption=true \
            --set storagenode.maxLvol="20" \
            --set storagenode.maxSnap="20" \
            --set storagenode.maxProv="150G" \
            --set storagenode.numDevices="3" \
            --set storagenode.dataNics=eth1 \
            --set storagenode.ifname=eth0 \
            --debug
        id: helm_install
        env:
          SBCLI_CMD: ${{ env.SBCLI_CMD }}
          NDCS: ${{ env.NDCS }}
          NPCS: ${{ env.NPCS }}
          BS: ${{ env.BS }}
          CHUNK_BS: ${{ env.CHUNK_BS }}
          KEY_NAME: "simplyblock-us-east-2.pem"
          SECRET_VALUE: ${{ secrets.simplyblock_us_east_2_pem }}
          BASTION_IP: "192.168.10.66"
          GRAFANA_ENDPOINT: "http://192.168.10.66/grafana"
          MNODES: "192.168.10.66"
          STORAGE_PRIVATE_IPS: "192.168.10.67 192.168.10.68 192.168.10.69"
          SEC_STORAGE_PRIVATE_IPS: "192.168.10.70"
          API_INVOKE_URL: "http://192.168.10.66/"
          K3S_MNODES: "192.168.10.135"
          NR_HUGEPAGES: "2048"


      # - name: Deploy SPDK-CSI with Helm
      #   run: |
      #     cd simplyblock-csi/charts/latest/spdk-csi
      #     helm install spdk-csi ./ \
      #       --namespace spdk-csi \
      #       --create-namespace \
      #       --set csiConfig.simplybk.uuid="${CLUSTER_ID}" \
      #       --set csiConfig.simplybk.ip="${API_INVOKE_URL}" \
      #       --set csiSecret.simplybk.secret="${CLUSTER_SECRET}" \
      #       --set image.simplyblock.tag="main" \
      #       --set logicalVolume.pool_name="testing1" \
      #       --set logicalVolume.snapshot="True" \
      #       --set image.spdkcsi.tag=latest \
      #       --set logicalVolume.distr_ndcs="${NDCS}" \
      #       --set logicalVolume.distr_npcs="${NPCS}" \
      #       --set storagenode.create=true \
      #       --set cachingnode.create=false \
      #       --set logicalVolume.encryption=true \
      #       --set storagenode.maxLvol="10" \
      #       --set storagenode.maxSnap="10" \
      #       --set storagenode.maxProv="150G" \
      #       --set storagenode.numDevices="3" \
      #       --set storagenode.dataNics=eth1 \
      #       --set storagenode.ifname=eth0
      #   id: helm_install
      #   env:
      #     SBCLI_CMD: ${{ env.SBCLI_CMD }}
      #     NDCS: ${{ env.NDCS }}
      #     NPCS: ${{ env.NPCS }}
      #     BS: ${{ env.BS }}
      #     CHUNK_BS: ${{ env.CHUNK_BS }}
      #     KEY_NAME: "simplyblock-us-east-2.pem"
      #     SECRET_VALUE: ${{ secrets.simplyblock_us_east_2_pem }}
      #     BASTION_IP: "192.168.10.66"
      #     GRAFANA_ENDPOINT: "http://192.168.10.66/grafana"
      #     MNODES: "192.168.10.66"
      #     STORAGE_PRIVATE_IPS: "192.168.10.67 192.168.10.68 192.168.10.69"
      #     SEC_STORAGE_PRIVATE_IPS: "192.168.10.70"
      #     API_INVOKE_URL: "http://192.168.10.66/"
      #     K3S_MNODES: "192.168.10.135"
      #     NR_HUGEPAGES: "2048"

      - name: Check Cluster Status
        run: |
          CLUSTER_API_GATEWAY_ENDPOINT="http://192.168.10.66/"
          CLUSTER_UUID="${CLUSTER_ID}"
          CLUSTER_SECRET="${CLUSTER_SECRET}"
          n=0
          until [ "$n" -ge 100 ]
          do
            response=$(curl -s -X GET "$CLUSTER_API_GATEWAY_ENDPOINT/cluster/$CLUSTER_UUID" \
              -H "Content-Type: application/json" \
              -H "Authorization: $CLUSTER_UUID $CLUSTER_SECRET")
            
            status=$(echo $response | jq -r '.results[0].status')
            
            if [ "$status" == "active" ]; then
                echo "Cluster status is active"
                exit 0
            fi
            
            echo "Cluster status is not active, current status: $status, retrying"
            n=$((n+1)) 
            sleep 20
          done
          
          if [ "$status" != "active" ]; then
              echo "Cluster is still not active, attempting manual activation."
              $SBCLI_CMD -d cluster activate $CLUSTER_ID || echo "Cluster activation attempt failed"
              sleep 30
              
              response=$(curl -s -X GET "$CLUSTER_API_GATEWAY_ENDPOINT/cluster/$CLUSTER_UUID" \
                  -H "Content-Type: application/json" \
                  -H "Authorization: $CLUSTER_UUID $CLUSTER_SECRET")
              
              status=$(echo $response | jq -r '.results[0].status')
              
              if [ "$status" != "active" ]; then
                  echo "Cluster is still not active after manual activation. Exiting."
                  exit 1
              fi
          fi
        env:
          SBCLI_CMD: ${{ env.SBCLI_CMD }}
          NDCS: ${{ env.NDCS }}
          NPCS: ${{ env.NPCS }}
          BS: ${{ env.BS }}


      - name: Record Test Start Time
        run: echo "TEST_START_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Setup Tests & Run Tests
        timeout-minutes: 200
        run: |
          cd $GITHUB_WORKSPACE/e2e
          pip install virtualenv
          python3 -m venv myenv
          source myenv/bin/activate
          python3 -m pip install -r requirements.txt
          echo "Running tests in namespace default"
          export CLUSTER_ID=${CLUSTER_ID}
          export CLUSTER_SECRET=${CLUSTER_SECRET}
          export API_BASE_URL=${API_INVOKE_URL}
          export BASTION_SERVER=${BASTION_IP}
          export KEY_NAME=${KEY_NAME} 
          export AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
          export AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}
          export AWS_REGION=${{ secrets.AWS_REGION }}
          export SBCLI_CMD=${SBCLI_CMD}
          export SSH_USER=root
          TESTNAME=""
          if [ -n "${{ github.event.inputs.testname }}" ]; then
            TESTNAME="--testname ${{ github.event.inputs.testname }}"
          fi
          python3 e2e.py $TESTNAME \
                  --ndcs $NDCS --npcs $NPCS --bs $BS --chunk_bs $CHUNK_BS --run_ha ${{ github.event.inputs.run_ha_test }} --run_k8s true
        env:
          SBCLI_CMD: ${{ env.SBCLI_CMD }}
          NDCS: ${{ env.NDCS }}
          NPCS: ${{ env.NPCS }}
          BS: ${{ env.BS }}
          CHUNK_BS: ${{ env.CHUNK_BS }}
          CLUSTER_ID: ${{ env.CLUSTER_ID }}
          CLUSTER_SECRET: ${{ env.CLUSTER_SECRET }}
          KEY_NAME: "simplyblock-us-east-2.pem"
          BASTION_IP: "192.168.10.66"
          MNODES: "192.168.10.66"
          API_INVOKE_URL: "http://192.168.10.66/"

      - name: Record Test End Time
        if: always()
        run: echo "TEST_END_TIME=$(date +%s)" >> $GITHUB_ENV

      - name: Calculate Total Time Taken
        if: always()
        run: |
          TEST_TIME=$(($TEST_END_TIME - $TEST_START_TIME))
          TEST_TIME_HOURS=$(($TEST_TIME / 3600))
          TEST_TIME_MINS=$((($TEST_TIME % 3600) / 60))
          TEST_TIME_SECS=$(($TEST_TIME % 60))
          echo "Test runtime: ${TEST_TIME_HOURS}h ${TEST_TIME_MINS}m ${TEST_TIME_SECS}s"
          echo "TEST_TIME_HOURS=$TEST_TIME_HOURS" >> $GITHUB_ENV
          echo "TEST_TIME_MINS=$TEST_TIME_MINS" >> $GITHUB_ENV
          echo "TEST_TIME_SECS=$TEST_TIME_SECS" >> $GITHUB_ENV

      - name: Parse test results
        if: always() && (github.event_name == 'schedule' || env.send_slack_notification == 'true')
        id: parse_results
        run: |
          cd $GITHUB_WORKSPACE/e2e/logs
          echo "Looking for the latest non-empty log file..."
          # Find the latest non-empty log file
          COUNTER=0
          MAX_ATTEMPTS=10
          while [ $COUNTER -lt $MAX_ATTEMPTS ]; do
            LATEST_LOG=$(ls -t *.log | head -n 1)
            if [ -s "$LATEST_LOG" ]; then
              echo "Found non-empty log file: $LATEST_LOG"
              break
            fi
            echo "Attempt $((COUNTER + 1)): No non-empty log file found. Retrying..."
            COUNTER=$((COUNTER + 1))
            sleep 1  # Add a small delay to avoid rapid looping
          done
          if [ ! -s "$LATEST_LOG" ]; then
            echo "No non-empty log file found after $MAX_ATTEMPTS attempts"
            exit 1
          fi
          echo "Parsing the identified log file: $LATEST_LOG"
          # Parse the identified log file
          echo "Total tests"
          TOTAL_TESTS=$(grep -i "Number of Total Cases" "$LATEST_LOG" | awk '{print $NF}')
          echo "number Passed tests"
          PASSED_TESTS=$(grep -i "Number of Passed Cases" "$LATEST_LOG" | awk '{print $NF}')
          echo "number Failed tests"
          FAILED_TESTS=$(grep -i "Number of Failed Cases" "$LATEST_LOG" | awk '{print $NF}')
          echo "number Skipped tests"
          SKIPPED_TESTS=$(grep -i "Number of Skipped Cases" "$LATEST_LOG" | awk '{print $NF}')
          echo "List Passed tests"
          PASSED_CASES=$(grep "PASSED CASE" "$LATEST_LOG" | awk -F 'INFO - | FAILED CASE' '{print $2}')
          echo "List Failed tests"
          FAILED_CASES=$(grep "FAILED CASE" "$LATEST_LOG" | awk -F 'INFO - | SKIPPED CASE' '{print $2}')
          echo "List Skipped tests"
          SKIPPED_CASES=$(grep "SKIPPED CASE" "$LATEST_LOG" | awk -F 'INFO - | SKIPPED CASE' '{print $2}')
          # Format passed and failed cases as bullet points
          echo "Adding PASSED cases with bullets: $PASSED_CASES"
          echo "Adding FAILED cases with bullets: $FAILED_CASES"
          echo "Adding SKIPPED cases with bullets: $SKIPPED_CASES"
          PASSED_CASES_BULLETS=$(echo "$PASSED_CASES" | awk '{printf "    • %s\n", $0}')
          FAILED_CASES_BULLETS=$(echo "$FAILED_CASES" | awk '{printf "    • %s\n", $0}')
          SKIPPED_CASES_BULLETS=$(echo "$SKIPPED_CASES" | awk '{printf "    • %s\n", $0}')
          echo "PASSED cases with bullets: $PASSED_CASES_BULLETS"
          echo "FAILED cases with bullets: $FAILED_CASES_BULLETS"
          echo "SKIPPED cases with bullets: $SKIPPED_CASES_BULLETS"
          echo "TOTAL_TESTS=${TOTAL_TESTS}"
          echo "PASSED_TESTS=${PASSED_TESTS}"
          echo "FAILED_TESTS=${FAILED_TESTS}"
          echo "SKIPPED_TESTS=${SKIPPED_TESTS}"
          echo "PASSED_CASES=${PASSED_CASES}"
          echo "FAILED_CASES=${FAILED_CASES}"
          echo "SKIPPED_CASES=${SKIPPED_CASES}"
          echo "PASSED_TESTS=${PASSED_TESTS}" >> $GITHUB_ENV
          echo "FAILED_TESTS=${FAILED_TESTS}" >> $GITHUB_ENV
          echo "SKIPPED_TESTS=${SKIPPED_TESTS}" >> $GITHUB_ENV
          echo "TOTAL_TESTS=${TOTAL_TESTS}" >> $GITHUB_ENV
          echo "PASSED_CASES<<EOF" >> $GITHUB_ENV
          echo "${PASSED_CASES}" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
          echo "FAILED_CASES<<EOF" >> $GITHUB_ENV
          echo "${FAILED_CASES}" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
          echo "SKIPPED_CASES<<EOF" >> $GITHUB_ENV
          echo "${SKIPPED_CASES}" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
          echo "PASSED_CASES_BULLETS<<EOF" >> $GITHUB_ENV
          echo "${PASSED_CASES_BULLETS}" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
          echo "FAILED_CASES_BULLETS<<EOF" >> $GITHUB_ENV
          echo "${FAILED_CASES_BULLETS}" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
          echo "SKIPPED_CASES_BULLETS<<EOF" >> $GITHUB_ENV
          echo "${SKIPPED_CASES_BULLETS}" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

      - name: Send Slack Notification
        if: always() && (github.event_name == 'schedule' || env.send_slack_notification == 'true')
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          GITHUB_SERVER_URL: ${{ github.server_url }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          S3_BUCKET_NAME: "simplyblock-e2e-test-logs"
          RUN_ID: ${{ github.run_id }}
          PASSED_TESTS: ${{ env.PASSED_TESTS }}
          FAILED_TESTS: ${{ env.FAILED_TESTS }}
          TOTAL_TESTS: ${{ env.TOTAL_TESTS }}
          PASSED_CASES: ${{ env.PASSED_CASES }}
          FAILED_CASES: ${{ env.FAILED_CASES }}
          SKIPPED_CASES: ${{ env.SKIPPED_CASES }}
          PASSED_CASES_BULLETS: ${{ env.PASSED_CASES_BULLETS }}
          FAILED_CASES_BULLETS: ${{ env.FAILED_CASES_BULLETS }}
          SKIPPED_CASES_BULLETS: ${{ env.SKIPPED_CASES_BULLETS }}
          BRANCH_NAME: ${{ github.ref_name }}
          TEST_TIME_HOURS: ${{ env.TEST_TIME_HOURS }}
          TEST_TIME_MINS: ${{ env.TEST_TIME_MINS }}
          TEST_TIME_SECS: ${{ env.TEST_TIME_SECS }}
          NDCS: ${{ env.NDCS }}
          NPCS: ${{ env.NPCS }}
          CHUNK_BS: ${{ env.CHUNK_BS }}
          BS: ${{ env.BS }}
        run: |
          GITHUB_RUN_URL="${GITHUB_SERVER_URL}/${GITHUB_REPOSITORY}/actions/runs/${RUN_ID}"
          AWS_LOGS_URL="http://192.168.10.164:9001/browser/e2e-run-logs/${RUN_ID}%2F"
          if [[ ${{ job.status }} == 'success' ]]; then
            OVERALL_STATUS=":white_check_mark: Overall Status: SUCCESS"
          else
            OVERALL_STATUS=":x: Overall Status: FAILURE <!channel>"
          fi

          TIME_TAKEN="${TEST_TIME_HOURS}h ${TEST_TIME_MINS}m ${TEST_TIME_SECS}s"

          MESSAGE="Python E2E K8s tests run triggered on branch *${BRANCH_NAME}*. \nTotal Time Taken to run the tests: ${TIME_TAKEN}. \n\n${OVERALL_STATUS}\nGitHub Run: ${GITHUB_RUN_URL}\nAWS Logs: ${AWS_LOGS_URL}\n\n*Configuration*: *NDCS: ${NDCS}, NPCS: ${NPCS}, Block Size: ${BS}, Chunk Block Size: ${CHUNK_BS}*\n\nTotal Tests: *${TOTAL_TESTS}*, Passed Tests: *${PASSED_TESTS}*, Failed Tests: *${FAILED_TESTS}*\n\n-- Test Cases Passed :white_check_mark:\n${PASSED_CASES_BULLETS}\n\n-- Test Cases Failed :x:\n${FAILED_CASES_BULLETS}\n\n-- Test Cases Skipped :x:\n${SKIPPED_CASES_BULLETS}"

          curl -X POST -H 'Content-type: application/json' --data "{\"text\":\"${MESSAGE}\"}" $SLACK_WEBHOOK_URL

      - name: Upload automation and docker logs to miniio
        run: |
          cd $GITHUB_WORKSPACE/e2e/
          python3 logs/upload_logs_to_miniio.py --k8s
        if: always()
        env:
          GITHUB_RUN_ID: ${{ github.run_id }}
          MINIO_ACCESS_KEY: "KxtpwblgG3AFDYJkyg8i"
          MINIO_SECRET_KEY: "Yae4q5wJU9ZBzJhdsUGzu9wWqON8o0ERU7nGbJER"
          BASTION_IP: "192.168.10.66"
          MNODES: "192.168.10.66"
          STORAGE_PRIVATE_IPS: "192.168.10.67 192.168.10.68 192.168.10.69"
          SEC_STORAGE_PRIVATE_IPS: "192.168.10.70"
          USER: "root"
      
      - name: Uninstall K3s agent on all nodes
        if: always() && (github.event_name == 'schedule' || env.cleanup_cluster == 'true')
        run: |
          helm uninstall -n spdk-csi spdk-csi || echo "No helm release found. Skipping uninstall."
          
          echo "[INFO] Deleting deployments..."
          kubectl delete deployments --all -n spdk-csi || echo "No deployments found. Skipping delete deployment."
          
          echo "[INFO] Deleting daemonsets..."
          kubectl delete daemonset --all -n spdk-csi || echo "No daemonsets found. Skipping delete."
          
          echo "[INFO] Deleting all pods..."
          kubectl delete pods --all -n spdk-csi --force --timeout=10s || echo "Pods not deleted within timeout."

          echo "[INFO] Waiting for all resources to be deleted..."
          timeout=120  # Max wait time (in seconds)
          interval=5  # Check every 5 seconds
          elapsed=0

          while [[ $(kubectl get all -n spdk-csi --no-headers 2>/dev/null | wc -l) -gt 0 && $elapsed -lt $timeout ]]; do
            echo "[INFO] Waiting for resources to be deleted... Elapsed: ${elapsed}s"
            sleep $interval
            elapsed=$((elapsed + interval))
          done

          if [[ $(kubectl get all -n spdk-csi --no-headers 2>/dev/null | wc -l) -eq 0 ]]; then
            echo "[SUCCESS] All resources deleted successfully."
          else
            echo "[WARNING] Resources were not deleted within the timeout of ${timeout}s."
          fi

          for node in $K3S_MNODES $STORAGE_PRIVATE_IPS $SEC_STORAGE_PRIVATE_IPS; do
            ssh -i ~/.ssh/simplyblock-us-east-2.pem  root@${node} "k3s-agent-uninstall.sh"
          done
          
          for node in $MNODES; do
            if ssh -i ~/.ssh/simplyblock-us-east-2.pem root@${node} "command -v $SBCLI_CMD" &>/dev/null; then
              ssh -i ~/.ssh/simplyblock-us-east-2.pem root@${node} "$SBCLI_CMD sn deploy-cleaner" || echo "[WARNING] Failed to run deploy-cleaner on $node"
            else
              echo "[WARNING] SBCLI_CMD not found on $node. Skipping deploy-cleaner."
            fi

            ssh -i ~/.ssh/simplyblock-us-east-2.pem root@${node} "rm -rf /etc/foundationdb/* || true" || echo "[WARNING] Failed to clean foundationdb on $node"
          done
        env:
          STORAGE_PRIVATE_IPS: "192.168.10.67 192.168.10.68 192.168.10.69"
          SEC_STORAGE_PRIVATE_IPS: "192.168.10.70"
          MNODES: "192.168.10.66"
          SBCLI_CMD: ${{ env.SBCLI_CMD }}

      - name: 'Cleanup build folder'
        run: |
          ls -la ./
          rm -rf ./* || true
          rm -rf ./.??* || true
          ls -la ./
          rm -rf /etc/rancher/k3s || true
